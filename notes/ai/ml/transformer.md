---
title: Transformer
---

# Transformer

- Tokenization - Embedding - Positional encoding - Transformer block - Attention
- 参考
  - [What Are Transformer Models and How Do They Work?](https://cohere.com/blog/what-are-transformer-models)
  - [Attention Is All You Need](https://arxiv.org/abs/1706.03762)
    - 2017
  - [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)
  - [The Transformer Family](https://lilianweng.github.io/posts/2020-04-07-the-transformer-family/)
    - 2020
  - https://www.zhihu.com/question/445556653/answer/3254012065

![](./ModalNet-21.png)
